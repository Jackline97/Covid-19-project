{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "maclious_final = pd.read_csv('data_maclious_final.csv',sep=',',encoding = \"ISO-8859-1\")\n",
    "white_final = pd.read_csv('data_white_final.csv',sep=',',encoding = \"ISO-8859-1\")\n",
    "unlabeled_final = pd.read_csv('data_final_version1.csv',sep=',',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unified_url</th>\n",
       "      <th>Reachable_URL</th>\n",
       "      <th>Time_stamp_if_exist</th>\n",
       "      <th>Way_back_archived</th>\n",
       "      <th>Freenom_top_level_domain</th>\n",
       "      <th>Previous_malicious_top_level_domain_TLD</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Wrong_spell_List</th>\n",
       "      <th>word_dic</th>\n",
       "      <th>Special_mark</th>\n",
       "      <th>sub_domain</th>\n",
       "      <th>Contain_IP_Adress</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>Alexa_rank</th>\n",
       "      <th>Status_code</th>\n",
       "      <th>Shortening service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://158.69.153.253</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://19covid-gouv12.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://3dforcovid.com</td>\n",
       "      <td>1</td>\n",
       "      <td>20200602061114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2922549</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://COVID--19-shop.rf.gd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16738</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://actualisatie.updateics-covid19.noez.me</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Unified_url  Reachable_URL  \\\n",
       "0                          http://158.69.153.253              1   \n",
       "1                      http://19covid-gouv12.com              1   \n",
       "2                          http://3dforcovid.com              1   \n",
       "3                    http://COVID--19-shop.rf.gd              1   \n",
       "4  http://actualisatie.updateics-covid19.noez.me              1   \n",
       "\n",
       "   Time_stamp_if_exist  Way_back_archived  Freenom_top_level_domain  \\\n",
       "0                    0                  0                         0   \n",
       "1                    0                  0                         0   \n",
       "2       20200602061114                  1                         0   \n",
       "3                    0                  0                         0   \n",
       "4                    0                  0                         0   \n",
       "\n",
       "   Previous_malicious_top_level_domain_TLD  Name_length  Wrong_spell_List  \\\n",
       "0                                        0            5                 0   \n",
       "1                                        0            8                 0   \n",
       "2                                        0            7                 0   \n",
       "3                                        0            7                 0   \n",
       "4                                        0           12                 0   \n",
       "\n",
       "   word_dic  Special_mark  sub_domain  Contain_IP_Adress  \\\n",
       "0  0.105263             0           3                  1   \n",
       "1  0.086957             1           1                  0   \n",
       "2  0.105263             0           1                  0   \n",
       "3  0.080000             1           2                  0   \n",
       "4  0.046512             1           3                  0   \n",
       "\n",
       "   levenshtein_distance  Alexa_rank  Status_code  Shortening service  \n",
       "0                     0           0          200                   0  \n",
       "1                     0           0          200                   0  \n",
       "2                     0     2922549          200                   0  \n",
       "3                     0       16738          200                   0  \n",
       "4                     0           0          200                   0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maclious_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_url = open(\"covid19-related-master/whitelist-domains.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_url_final = []\n",
    "for i in white_url:\n",
    "    white_url_final.append('https://'+i[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_final['Unified_url'] = white_url_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unified_url</th>\n",
       "      <th>Reachable_URL</th>\n",
       "      <th>Time_stamp_if_exist</th>\n",
       "      <th>Way_back_archived</th>\n",
       "      <th>Freenom_top_level_domain</th>\n",
       "      <th>Previous_malicious_top_level_domain_TLD</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Wrong_spell_List</th>\n",
       "      <th>word_dic</th>\n",
       "      <th>Special_mark</th>\n",
       "      <th>sub_domain</th>\n",
       "      <th>Contain_IP_Adress</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>Alexa_rank</th>\n",
       "      <th>Status_code</th>\n",
       "      <th>Shortening service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://akkure4covid.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.contracovid.com.br</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://app.contracovid.com.br</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://auxilio.caixa.gov.br</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://bag-coronavirus.ch</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Unified_url  Reachable_URL  Time_stamp_if_exist  \\\n",
       "0        https://akkure4covid.com              1                    0   \n",
       "1  https://api.contracovid.com.br              1                    0   \n",
       "2  https://app.contracovid.com.br              1                    0   \n",
       "3    https://auxilio.caixa.gov.br              1                    0   \n",
       "4      https://bag-coronavirus.ch              1                    0   \n",
       "\n",
       "   Way_back_archived  Freenom_top_level_domain  \\\n",
       "0                  0                         0   \n",
       "1                  0                         0   \n",
       "2                  0                         0   \n",
       "3                  0                         0   \n",
       "4                  0                         0   \n",
       "\n",
       "   Previous_malicious_top_level_domain_TLD  Name_length  Wrong_spell_List  \\\n",
       "0                                        0            6                 0   \n",
       "1                                        0            6                 0   \n",
       "2                                        0            6                 0   \n",
       "3                                        0            8                 0   \n",
       "4                                        0            3                 0   \n",
       "\n",
       "   word_dic  Special_mark  sub_domain  Contain_IP_Adress  \\\n",
       "0  0.105263             0           1                  0   \n",
       "1  0.080000             0           3                  0   \n",
       "2  0.080000             0           3                  0   \n",
       "3  0.086957             0           3                  0   \n",
       "4  0.095238             1           1                  0   \n",
       "\n",
       "   levenshtein_distance  Alexa_rank  Status_code  Shortening service  \n",
       "0                     4           0          200                   0  \n",
       "1                     8           0          200                   0  \n",
       "2                     8           0          200                   0  \n",
       "3                    10           0          200                   0  \n",
       "4                     5           0          200                   0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unified_url</th>\n",
       "      <th>Reachable_URL</th>\n",
       "      <th>Time_stamp_if_exist</th>\n",
       "      <th>Way_back_archived</th>\n",
       "      <th>Freenom_top_level_domain</th>\n",
       "      <th>Previous_malicious_top_level_domain_TLD</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Wrong_spell_List</th>\n",
       "      <th>word_dic</th>\n",
       "      <th>Special_mark</th>\n",
       "      <th>sub_domain</th>\n",
       "      <th>Contain_IP_Adress</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>Alexa_rank</th>\n",
       "      <th>Status_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://coronavirusemploymentservices.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26.799492</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://coronavirusen.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://coronavirusencasa.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18.532995</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://coronavirusencolombia.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20.697970</td>\n",
       "      <td>8926414</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://coronavirusend.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16.845178</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Unified_url  Reachable_URL  \\\n",
       "0  http://coronavirusemploymentservices.com              0   \n",
       "1                  http://coronavirusen.com              0   \n",
       "2              http://coronavirusencasa.com              0   \n",
       "3          http://coronavirusencolombia.com              0   \n",
       "4                 http://coronavirusend.com              0   \n",
       "\n",
       "   Time_stamp_if_exist  Way_back_archived  Freenom_top_level_domain  \\\n",
       "0                    0                  0                         0   \n",
       "1                    0                  0                         0   \n",
       "2                    0                  0                         0   \n",
       "3                    0                  0                         0   \n",
       "4                    0                  0                         0   \n",
       "\n",
       "   Previous_malicious_top_level_domain_TLD  Name_length  Wrong_spell_List  \\\n",
       "0                                        0            6                 0   \n",
       "1                                        0            5                 0   \n",
       "2                                        0            6                 0   \n",
       "3                                        0            6                 0   \n",
       "4                                        0            5                 0   \n",
       "\n",
       "   word_dic  Special_mark  sub_domain  Contain_IP_Adress  \\\n",
       "0  0.050000             0           2                  0   \n",
       "1  0.083333             0           2                  0   \n",
       "2  0.071429             0           2                  0   \n",
       "3  0.062500             0           2                  0   \n",
       "4  0.080000             0           2                  0   \n",
       "\n",
       "   levenshtein_distance  Alexa_rank  Status_code  \n",
       "0             26.799492           0          200  \n",
       "1             16.500000           0          200  \n",
       "2             18.532995           0          200  \n",
       "3             20.697970     8926414          200  \n",
       "4             16.845178           0          200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "def get_hostname_from_url(url):\n",
    "    hostname = url\n",
    "    # TODO: Put this pattern in patterns.py as something like - get_hostname_pattern.\n",
    "    pattern = \"https://|http://|www.|https://www.|http://www.\"\n",
    "    pre_pattern_match = re.search(pattern, hostname)\n",
    "\n",
    "    if pre_pattern_match:\n",
    "        hostname = hostname[pre_pattern_match.end():]\n",
    "        post_pattern_match = re.search(\"/\", hostname)\n",
    "        if post_pattern_match:\n",
    "            hostname = hostname[:post_pattern_match.start()]\n",
    "\n",
    "    return hostname\n",
    "\n",
    "def levenshtein(source,target):\n",
    "    if len(source) < len(target):\n",
    "        return levenshtein(target, source)\n",
    "\n",
    "    # So now we have len(source) >= len(target).\n",
    "    if len(target) == 0:\n",
    "        return len(source)\n",
    "    source = np.array(tuple(source))\n",
    "    target = np.array(tuple(target))\n",
    "    previous_row = np.arange(target.size + 1)\n",
    "    for s in source:\n",
    "        # Insertion (target grows longer than source):\n",
    "        current_row = previous_row + 1\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                np.add(previous_row[:-1], target != s))\n",
    "\n",
    "        # Deletion (target grows shorter than source):\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                current_row[0:-1] + 1)\n",
    "\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://158.69.153.253\n",
      "http://19covid-gouv12.com\n",
      "http://3dforcovid.com\n",
      "http://COVID--19-shop.rf.gd\n",
      "http://actualisatie.updateics-covid19.noez.me\n",
      "http://advancedaesthetics.ch\n",
      "http://aide-covid19.tn\n",
      "http://airbnb.id-covid19.com\n",
      "http://amazon.co.jp.initiativescompany-news-covid19-20200316token4787f6f3e205921236.buzz\n",
      "http://amazon.co.jp.initiativescompany-news-covid19-20200316token4787f6f3e205923534.buzz\n",
      "http://amazon.co.jp.initiativescompany-news-covid19-20200316token4787f6f3e205926666.buzz\n",
      "http://amelenedez.com\n",
      "http://amelzendez.com\n",
      "http://americanascovidshop.com\n",
      "http://amqelendez.com\n",
      "http://andreakristi.000webhostapp.com\n",
      "http://anti-coronavirus.sk\n",
      "http://anti-covid.sk\n",
      "http://anti-covid.supplies\n",
      "http://anti-covid19.sk\n",
      "http://anticovid-19.sk\n",
      "http://artscovid.org\n",
      "http://aruba-covid19.u720493s8q.ha004.t.justns.ru\n",
      "http://ateaseoutfitters.com\n",
      "http://atlantabeatscovid.com\n",
      "http://atlantabeatscovid.org\n",
      "http://auxilioemergencialcovid.com\n",
      "http://ayudadigitalcovid.org\n",
      "http://ayyappantat.com\n",
      "http://bantaycovid.com\n",
      "http://barcelonaneoville.com.br\n",
      "http://bb-iscoronas.it\n",
      "http://beccahorner.com\n",
      "http://bell-covid19.com\n",
      "http://berita-covid-19-terkini-tasikmalaya.000webhostapp.com\n",
      "http://bhleon.com-do.serfidelo.com\n",
      "http://bit.ly\n",
      "http://bizrak.com\n",
      "http://bodicia.com.ru\n",
      "http://bokepspecialcovid19.event-indo.com\n",
      "http://bokepviral.19covidd.com\n",
      "http://bp-formularios-covid19.azurewebsites.net\n",
      "http://bravecovid.com\n",
      "http://business-facebook-covid19.com\n",
      "http://caninetags.ga\n",
      "http://carrefourcovid.com\n",
      "http://cbsrealitychase.com\n",
      "http://cdestudiantes.com\n",
      "http://cecollc.com\n",
      "http://chase-covid19s.com\n",
      "http://chase7-covid.com\n",
      "http://chasecovid19s.com\n",
      "http://chasecovid19t.com\n",
      "http://chasecovid19v.com\n",
      "http://cherrydancefitness.co.uk\n",
      "http://childcarecorona.com\n",
      "http://chirurgiehmrcovid.com\n",
      "http://cinenagari.com\n",
      "http://click.cocovid.co\n",
      "http://cmattayers.com\n",
      "http://cocovid.co\n",
      "http://combatecovid.org\n",
      "http://computecovid.com\n",
      "http://copingwithcovid.blog\n",
      "http://corona-live.net\n",
      "http://corona-masr2.com\n",
      "http://corona-masr21.com\n",
      "http://corona-masr3.com\n",
      "http://corona-nearby.com\n",
      "http://corona-virus-anonymous.org\n",
      "http://corona-virusus.com\n",
      "http://corona19covid.000webhostapp.com\n",
      "http://coronabye.com\n",
      "http://coronadocruisers.com\n",
      "http://coronaent.com.hk\n",
      "http://coronaextra.com.au\n",
      "http://coronaflexx.000webhostapp.com\n",
      "http://coronagame1.co.vu\n",
      "http://coronagame2.co.vu\n",
      "http://coronagame3.co.vu\n",
      "http://coronagame4.co.vu\n",
      "http://coronamask.space\n",
      "http://coronanow.kr\n",
      "http://coronasmask.space\n",
      "http://coronate-sounds.000webhostapp.com\n",
      "http://coronation.ml\n",
      "http://coronatoken.org\n",
      "http://coronavgame1.atwebpages.com\n",
      "http://coronavgame2.atwebpages.com\n",
      "http://coronavgame3.atwebpages.com\n",
      "http://coronavirus-help.uk\n",
      "http://coronavirus-in.space\n",
      "http://coronavirus-news.org.uk\n",
      "http://coronavirus-v-mire.ru\n",
      "http://coronavirusbacktoreality.com\n",
      "http://coronavirusfactory.com\n",
      "http://coronavirusfeedback.com\n",
      "http://coronavirusfinancial.net\n",
      "http://coronavirushazard.com\n",
      "http://coronavirusinasec.000webhostapp.com\n",
      "http://coronavirusnews.000webhostapp.com\n",
      "http://coronavirusonooeir.huidps.com\n",
      "http://coronavirusonooeir.luxciosoiop.com\n",
      "http://coronavirussms.com\n",
      "http://coronavirustrouble.com\n",
      "http://coronavirusu.info\n",
      "http://coronawatch.eu\n",
      "http://coronawire.com\n",
      "http://coronawire.in\n",
      "http://coronawires.com\n",
      "http://coronbeer.com\n",
      "http://cottonbeatscovid.com\n",
      "http://courseaholic.com\n",
      "http://covid--19-shop.rf.gd\n",
      "http://covid-19.bdtime.news\n",
      "http://covid-19.xxx-wa.com\n",
      "http://covid-192.godaddysites.com\n",
      "http://covid-19art.com\n",
      "http://covid-19coronavirus.co.uk\n",
      "http://covid-19finance.co.uk\n",
      "http://covid-19rc.com\n",
      "http://covid.seguranca-bb.info\n",
      "http://covid19---shop.rf.gd\n",
      "http://covid19-credits.com\n",
      "http://covid19-finance.co.uk\n",
      "http://covid19-infor.net\n",
      "http://covid19-seguranca.autosmsbb.com\n",
      "http://covid19-survei.000webhostapp.com\n",
      "http://covid19-vat.rf.gd\n",
      "http://covid19.id-airbnb.com\n",
      "http://covid19.seguranca-bb.info\n",
      "http://covid19bireyseliadeniz.com\n",
      "http://covid19evdekalaidatinial.com\n",
      "http://covid19fund.co.uk\n",
      "http://covid19healthcare.000webhostapp.com\n",
      "http://covid19hosting.co.uk\n",
      "http://covid19lssuedbill.com\n",
      "http://covid19partnership.000webhostapp.com\n",
      "http://covid19peticija.000webhostapp.com\n",
      "http://covid19retailpulselive.com\n",
      "http://covid19voip.com\n",
      "http://covid2019colpatria.com.co\n",
      "http://covidcro.tk\n",
      "http://covidguide.guru\n",
      "http://covidi9.gq\n",
      "http://covidreamz.com\n",
      "http://covidsome.com\n",
      "http://cracovidfunds.com\n",
      "http://craemrcovid19.com\n",
      "http://crookedcovid.com\n",
      "http://crushcovid.net\n",
      "http://csam-corona.be\n",
      "http://curbsidecovid.com\n",
      "http://cutt.ly\n",
      "http://dailycorona.bitbyteplay.com\n",
      "http://daneili-corus.com\n",
      "http://dati-covid19-psd2.000webhostapp.com\n",
      "http://dentalleadgroup.com\n",
      "http://descovid-19.com\n",
      "http://dlwbfire.org\n",
      "http://dostaana.ml\n",
      "http://dtipgifts.com\n",
      "http://ecolenefiber.com\n",
      "http://ecovida.ru\n",
      "http://edigishoppee.com\n",
      "http://edumetrix.io\n",
      "http://eecovid19-support150.hyundaigiadinhsaigon.com\n",
      "http://envisioncm.com\n",
      "http://escalainicial.com.ar\n",
      "http://eshop-COVID19.rf.gd\n",
      "http://eshop-covid19.rf.gd\n",
      "http://evnt.com.br\n",
      "http://faq-coronavirus-financial-help.lsign.site\n",
      "http://faq-coronavirus-financial-help.nsign.me\n",
      "http://financingcovid.com\n",
      "http://firealarmcemen.com\n",
      "http://flatheadcovid.org\n",
      "http://fmcg-patterns.com\n",
      "http://footytube.top\n",
      "http://forgecovid.com\n",
      "http://frateemedia.com\n",
      "http://fushet.com\n",
      "http://gcoronag.000webhostapp.com\n",
      "http://gelaallc.com\n",
      "http://gigaplay.com.br\n",
      "http://goovcovid19.com\n",
      "http://gouvcanada-covid19.com\n",
      "http://hackingcovid.info\n",
      "http://hansonbalirunoug.com\n",
      "http://help-corona.cn\n",
      "http://helptoavoidcoronaa.000webhostapp.com\n",
      "http://highbrowclothing.com\n",
      "http://homologacao.xocovid19.com.br\n",
      "http://id-covid19.com\n",
      "http://informecovid.com\n",
      "http://ing.csam-corona.be\n",
      "http://ing.securecovid-19.noez.me\n",
      "http://intellicovid.com\n",
      "http://intercovid.com\n",
      "http://iowacovid.com\n",
      "http://iremoscombaterocovid.ml\n",
      "http://irs-gov.uc.r.appspot.com\n",
      "http://ita-covid19.com\n",
      "http://itacontracovid-19.ml\n",
      "http://italy-covid19.u720553s9g.ha004.t.justns.ru\n",
      "http://ithinkihavecovid.com\n",
      "http://jacarandascovid.com\n",
      "http://jararandascovid.com\n",
      "http://jasminettv.com\n",
      "http://join-whatsapp-bokep62.covid99.gq\n",
      "http://jshirt.it\n",
      "http://kampcbation.info\n",
      "http://keolis-covid.com\n",
      "http://kiwiyazilim.com\n",
      "http://kylebeard.com\n",
      "http://lanzarotecovid.com\n",
      "http://laylaraephoto.com\n",
      "http://lifelinen.com\n",
      "http://magalu-combate-ao-corona.com\n",
      "http://mail.covid-19.xxx-wa.com\n",
      "http://manchoujouser.com\n",
      "http://mapacovid.com\n",
      "http://mascarillasparacovid.com\n",
      "http://masry-corona51.com\n",
      "http://mastermovesltd.com\n",
      "http://mbhydro-covid19.com\n",
      "http://mcovid.com\n",
      "http://mediterraneosantamarinella.com\n",
      "http://mersrekdocuments.ir\n",
      "http://midiaplural.com.br\n",
      "http://mlskitchensmanchester.com\n",
      "http://moabcovid.org\n",
      "http://mortgageks.com\n",
      "http://mradani.ml\n",
      "http://mygpstrip.net\n",
      "http://nellyreifler.com\n",
      "http://nepalcoronavirus2.000webhostapp.com\n",
      "http://neraretionbriesx.club\n",
      "http://netflix-covid-19.com\n",
      "http://newcovid19unread.z13.web.core.windows.net\n",
      "http://news.att-covid19.com\n",
      "http://nimbleurbia53.com\n",
      "http://no-covid.online\n",
      "http://nocovid.fun\n",
      "http://notmycovid.org\n",
      "http://nr01petitieonline-covid19byfacebook.gq\n",
      "http://nxt27893.nextadmin.hu\n",
      "http://oceansapparel.com\n",
      "http://odessavscovid.info\n",
      "http://oldschool.runescape-covid-19.info\n",
      "http://onlnne.com\n",
      "http://orecon.co.jp\n",
      "http://parismomes.fr\n",
      "http://partners-covid.org\n",
      "http://partnerscovid.org\n",
      "http://pastcovid.com\n",
      "http://peduli-corona.wikaba.com\n",
      "http://permovqu.com\n",
      "http://pescaturismocorona.it\n",
      "http://piocppocodso.blob.core.windows.net\n",
      "http://plantingvelve.com\n",
      "http://playdomain53.com\n",
      "http://pledge-againstt-corona.000webhostapp.com\n",
      "http://politicovid.com\n",
      "http://portal.auone.jp-verifykey.covid-191.com\n",
      "http://portsmouth.buzz\n",
      "http://pre-covid.info\n",
      "http://previnadocoronasuavida.com\n",
      "http://previnasedocoronavirus.com\n",
      "http://pulsagratiscorona.000webhostapp.com\n",
      "http://rcconstrutora.com.br\n",
      "http://recovid.us\n",
      "http://register-participatecoronafreecoins300.mrbonus.com\n",
      "http://register-toparticipateviruscoronafree300coin.mrbonus.com\n",
      "http://remittancefiles.com\n",
      "http://rijosfoods.com.br\n",
      "http://rogers-covid19.com\n",
      "http://runescape-covid19.info\n",
      "http://saicoronadeixanoistrabalhar.com\n",
      "http://sajayagroup.com\n",
      "http://seeannsave.com\n",
      "http://shop---covid19.rf.gd\n",
      "http://shop--covid-19.rf.gd\n",
      "http://shop--covid19.rf.gd\n",
      "http://shop-covid19.rf.gd\n",
      "http://shop-sars-covid19.rf.gd\n",
      "http://shopcovid-19.rf.gd\n",
      "http://shops-covid-19.rf.gd\n",
      "http://shopscovid19.rf.gd\n",
      "http://sicurezza-covid19.com\n",
      "http://simplyoneden.com\n",
      "http://simplysororitypackets.com\n",
      "http://skcovid.com\n",
      "http://skcovid.org\n",
      "http://solidarite-covid.org\n",
      "http://spokanecovid.com\n",
      "http://standagainstcovid.org\n",
      "http://starilionpla.website\n",
      "http://stopcorona.org\n",
      "http://stopcovid.store\n",
      "http://storage.googleapis.com\n",
      "http://storiesofcovid.com\n",
      "http://summergirlfilms.com\n",
      "http://supperbelle.com\n",
      "http://t-uber.me\n",
      "http://t-ubersa.com\n",
      "http://taikisushi.com\n",
      "http://tarjeta-bci.cf\n",
      "http://testkitcovid.net\n",
      "http://testkitcovid.org\n",
      "http://thaiaichi.co.th\n",
      "http://thechristianwardrobe.us\n",
      "http://thusdaycoronaupdae.blob.core.windows.net\n",
      "http://thxcovid.com\n",
      "http://todoscontraocovid19.com\n",
      "http://todosjuntoscontraocovid.com\n",
      "http://topbrokersrealty.icu\n",
      "http://toyswithpizzazz.com.au\n",
      "http://trackcoronavirus.com\n",
      "http://trackcovid.app\n",
      "http://trainingcanine.ga\n",
      "http://transferenciasscotiabankk-chile-covid.gq\n",
      "http://trenv.coronavideo3.tk\n",
      "http://trustedproductreview.com\n",
      "http://twcindia.com\n",
      "http://tzetta.com\n",
      "http://uberpromocovid19.000webhostapp.com\n",
      "http://uk-covid-19-relieve.com\n",
      "http://uman4covid.org\n",
      "http://us-coronavirus-cases-state-by-state.afyfr.com\n",
      "http://usavscovid.com\n",
      "http://vamosacabcomocorona.com\n",
      "http://vamoscombaterocoronanaosaiadecasa.com\n",
      "http://vergognacovid.com\n",
      "http://verizoncovid-12.com\n",
      "http://videoonlinefrecorona.xyz\n",
      "http://villacorona.pl\n",
      "http://virusscoronas.000webhostapp.com\n",
      "http://virys-covid19.ru\n",
      "http://vivadiagcovid.com\n",
      "http://volontaire-covid.com\n",
      "http://volontairescovid.com\n",
      "http://vvho-dropb0xcloud.selfip.com\n",
      "http://wearecovid.com\n",
      "http://webbfilms.co.uk\n",
      "http://wefightcovid.se\n",
      "http://welcometocoronado.com\n",
      "http://whatcoronavirus.com\n",
      "http://whereiscovid.info\n",
      "http://wintexgroup-cn.com\n",
      "http://www.4mysecure-facebookcovid19petition.cf\n",
      "http://www.airbnb.id-covid19.com\n",
      "http://www.americanascovidshop.com\n",
      "http://www.brightparcel.com\n",
      "http://www.brunoespanha.com\n",
      "http://www.cbsrealitychase.com\n",
      "http://www.cherrydancefitness.co.uk\n",
      "http://www.cine.com.uy\n",
      "http://www.coronavirusonooeir.huidps.com\n",
      "http://www.covid-19challengecoin.com\n",
      "http://www.covidvirus.guru\n",
      "http://www.dailycorona.bitbyteplay.com\n",
      "http://www.eater.com\n",
      "http://www.gov-ca-covid19.org\n",
      "http://www.iacovides.com\n",
      "http://www.im4free.com\n",
      "http://www.irs.org\n",
      "http://www.irshelpcovid19.com\n",
      "http://www.ita-covid19.com\n",
      "http://www.itaucovid19.com\n",
      "http://www.koharrhealth.com\n",
      "http://www.lamalug.org\n",
      "http://www.lovecelebrities.com\n",
      "http://www.mediterraneosantamarinella.com\n",
      "http://www.n95mask-covid19.com\n",
      "http://www.nellyreifler.com\n",
      "http://www.netflix-covid-19.com\n",
      "http://www.peduli-corona.wikaba.com\n",
      "http://www.pescaturismocorona.it\n",
      "http://www.plantingvelve.com\n",
      "http://www.promo-covid19-neftlix.ml\n",
      "http://www.register-participatecoronafreecoins300.mrbonus.com\n",
      "http://www.reguster-forparticipateinthecorona-freecoin300.mrbonus.com\n",
      "http://www.rogers-covid19.com\n",
      "http://www.stpl.ca\n",
      "http://www.tzetta.com\n",
      "http://www.wailmegensa.com\n",
      "http://www.welcometocoronado.com\n",
      "http://www.wfb-wa-identity-confirmation-now.agency\n",
      "http://www4-irs-gov.uc.r.appspot.com\n",
      "http://xetoancau.vn\n",
      "http://xocovid19.com.br\n",
      "http://zendesk-covid19.org\n",
      "http://zonasegurabeta.viabcp-covid19.\n"
     ]
    }
   ],
   "source": [
    "confirmed_phishing_website = []\n",
    "f = open(\"ConfirmedPhishing.txt\", \"r\")\n",
    "for x in f:\n",
    "    print('http://'+ x[3:-4])\n",
    "    confirmed_phishing_website.append('http://'+ x[3:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def cal_min_lev(source, target):\n",
    "    min_dis_list = []\n",
    "    for i in tqdm(source):\n",
    "        i  = get_hostname_from_url(i)\n",
    "        temp_list = []\n",
    "        for j in target:\n",
    "            j = get_hostname_from_url(j)\n",
    "            temp_list.append(levenshtein(i,j))\n",
    "        min_dis_list.append(min(temp_list))\n",
    "    return min_dis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [00:28<00:00, 13.88it/s]\n"
     ]
    }
   ],
   "source": [
    "lev_mal = cal_min_lev(maclious_final['Unified_url'],confirmed_phishing_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maclious_final['levenshtein_distance'] = lev_mal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:07<00:00, 13.52it/s]\n"
     ]
    }
   ],
   "source": [
    "lev_whi = cal_min_lev(white_final['Unified_url'],confirmed_phishing_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_final['levenshtein_distance'] = lev_whi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229489/229489 [4:47:21<00:00, 13.31it/s]  \n"
     ]
    }
   ],
   "source": [
    "lev_unlabel = cal_min_lev(unlabeled_final['Unified_url'],confirmed_phishing_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_final['levenshtein_distance'] = lev_unlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "phish_url = []\n",
    "phish_date = []\n",
    "f1 = open('phishtank_openphish_xforce_2020/openphish.json')\n",
    "Phish_data1 = json.load(f1)\n",
    "for url in Phish_data1:\n",
    "    m = url['url']\n",
    "    if m[:5] == 'https':\n",
    "        temp = m[8:]\n",
    "        try:\n",
    "            post_pattern_match = re.search(\"/\", temp)\n",
    "            hostname = temp[:post_pattern_match.start()]\n",
    "            phish_url.append('https://'+hostname)\n",
    "            phish_date.append(int(url['date'][0:4]))\n",
    "        except AttributeError:    \n",
    "            phish_url.append('https://'+hostname)\n",
    "            phish_date.append(int(url['date'][0:4]))\n",
    "    elif m[:5] == 'http:':\n",
    "        temp = m[7:]\n",
    "        try:\n",
    "            post_pattern_match = re.search(\"/\", temp)\n",
    "            hostname = temp[:post_pattern_match.start()]\n",
    "            phish_url.append('https://'+hostname)\n",
    "            phish_date.append(int(url['date'][0:4]))\n",
    "        except AttributeError:    \n",
    "            phish_url.append('https://'+hostname)\n",
    "            phish_date.append(int(url['date'][0:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "phish_url_2 = []\n",
    "phish_date_2 = []\n",
    "f2 = open('phishtank_openphish_xforce_2020/phishtank.json')\n",
    "Phish_data2 = json.load(f2)\n",
    "for url in Phish_data2:\n",
    "    m = url['url']\n",
    "    if m[:5] == 'https':\n",
    "        temp = m[8:]\n",
    "        try:\n",
    "            post_pattern_match = re.search(\"/\", temp)\n",
    "            hostname = temp[:post_pattern_match.start()]\n",
    "            phish_url_2.append('https://'+hostname)\n",
    "            phish_date_2.append(int(url['date'][0:4]))\n",
    "        except AttributeError:    \n",
    "            phish_url_2.append('https://'+hostname)\n",
    "            phish_date_2.append(int(url['date'][0:4]))\n",
    "    elif m[:5] == 'http:':\n",
    "        temp = m[7:]\n",
    "        try:\n",
    "            post_pattern_match = re.search(\"/\", temp)\n",
    "            hostname = temp[:post_pattern_match.start()]\n",
    "            phish_url_2.append('https://'+hostname)\n",
    "            phish_date_2.append(int(url['date'][0:4]))\n",
    "        except AttributeError:    \n",
    "            phish_url_2.append('https://'+hostname)\n",
    "            phish_date_2.append(int(url['date'][0:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "phish_url_3 = []\n",
    "phish_date_3 = []\n",
    "f3 = open('phishtank_openphish_xforce_2020/xforce.json')\n",
    "Phish_data3 = json.load(f3)\n",
    "for url in Phish_data3:\n",
    "    m = url['url']\n",
    "    if m[:5] == 'https':\n",
    "        temp = m[8:]\n",
    "        try:\n",
    "            post_pattern_match = re.search(\"/\", temp)\n",
    "            hostname = temp[:post_pattern_match.start()]\n",
    "            phish_url_3.append('https://'+hostname)\n",
    "            phish_date_3.append(int(url['date'][0:4]))\n",
    "        except AttributeError:    \n",
    "            phish_url_3.append('https://'+hostname)\n",
    "            phish_date_3.append(int(url['date'][0:4]))\n",
    "    elif m[:5] == 'http:':\n",
    "        temp = m[7:]\n",
    "        try:\n",
    "            post_pattern_match = re.search(\"/\", temp)\n",
    "            hostname = temp[:post_pattern_match.start()]\n",
    "            phish_url_3.append('https://'+hostname)\n",
    "            phish_date_3.append(int(url['date'][0:4]))\n",
    "        except AttributeError:    \n",
    "            phish_url_3.append('https://'+hostname)\n",
    "            phish_date_3.append(int(url['date'][0:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "phish_all = np.unique(phish_url + phish_url_2 + phish_url_3)\n",
    "# phish_date_all = phish_date + phish_date_2 + phish_date_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98251\n"
     ]
    }
   ],
   "source": [
    "print(len(phish_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordninja\n",
    "from math import log\n",
    "def Extract_FTLD(List_all):\n",
    "    Freenom_top_level_domain = []\n",
    "    for i in List_all:\n",
    "        if i[-2:] == 'ml':\n",
    "            Freenom_top_level_domain.append(1)\n",
    "        elif i[-2:] == 'cf':\n",
    "            Freenom_top_level_domain.append(1)\n",
    "        elif i[-2:] == 'gq':\n",
    "            Freenom_top_level_domain.append(1)\n",
    "        elif i[-2:] == 'tk':\n",
    "            Freenom_top_level_domain.append(1)\n",
    "        elif i[-2:] == 'ga':\n",
    "            Freenom_top_level_domain.append(1)\n",
    "        else:\n",
    "            Freenom_top_level_domain.append(0)\n",
    "    return Freenom_top_level_domain\n",
    "\n",
    "def Previous_MTLD(List_all):\n",
    "# According to https://blogs.akamai.com/2019/10/a-view-into-top-level-domain-tld-abuse.html?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+TheAkamaiBlog+%28The+Akamai+Blog%29\n",
    "# According to https://www.anomali.com/blog/abusing-the-mali-cctld-ml-to-target-dutch-organisations\n",
    "    Previous_malicious_top_level_domain_TLD = []\n",
    "    for i in List_all:\n",
    "        if i[-2:] == 'ml':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'cf':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'so':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-4:] == 'loan':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-5:] == 'tokyo':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-5:] == 'trade':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-6:] == 'stream':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-3:] == 'bid':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-3:] == 'icu':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-3:] == 'gdn':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-3:] == 'win':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-4:] == 'work':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-4:] == 'desi':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-4:] == 'pics':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'gq':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'tk':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'vg':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'ga':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'to':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'cc':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'hk':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'pw':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'fm':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        elif i[-2:] == 'la':\n",
    "            Previous_malicious_top_level_domain_TLD.append(1)\n",
    "        else:\n",
    "            Previous_malicious_top_level_domain_TLD.append(0)\n",
    "    return Previous_malicious_top_level_domain_TLD\n",
    "\n",
    "def mixed_feature(List_all):\n",
    "    # Build a cost dictionary, assuming Zipf's law and cost = -math.log(probability).\n",
    "    # words = open(\"words-by-frequency.txt\").read().split()\n",
    "    # wordcost = dict((k, log((i+1)*log(len(words)))) for i,k in enumerate(words))\n",
    "    # maxword = max(len(x) for x in words)\n",
    "\n",
    "    def infer_spaces(s):\n",
    "        \"\"\"Uses dynamic programming to infer the location of spaces in a string\n",
    "        without spaces.\"\"\"\n",
    "\n",
    "        # Find the best match for the i first characters, assuming cost has\n",
    "        # been built for the i-1 first characters.\n",
    "        # Returns a pair (match_cost, match_length).\n",
    "        def best_match(i):\n",
    "            candidates = enumerate(reversed(cost[max(0, i-maxword):i]))\n",
    "            return min((c + wordcost.get(s[i-k-1:i], 9e999), k+1) for k,c in candidates)\n",
    "\n",
    "        # Build the cost array.\n",
    "        cost = [0]\n",
    "        for i in range(1,len(s)+1):\n",
    "            c,k = best_match(i)\n",
    "            cost.append(c)\n",
    "\n",
    "        # Backtrack to recover the minimal-cost string.\n",
    "        out = []\n",
    "        i = len(s)\n",
    "        while i>0:\n",
    "            c,k = best_match(i)\n",
    "            assert c == cost[i]\n",
    "            out.append(s[i-k:i])\n",
    "            i -= k\n",
    "\n",
    "        return \" \".join(reversed(out))\n",
    "\n",
    "    # This would take some time\n",
    "    word_dic = []\n",
    "    number_mark = []\n",
    "    Name_length = []\n",
    "    Wrong_spell = [\"cov1d\",\"c0v1d\",\"c0vid\",\"c0rona\",\"c0r0na\",\"cor0na\",\"v1rus\",\"coivd\",'co1vd']\n",
    "    Wrong_spell = Wrong_spell \n",
    "    Wrong_spell_List = []\n",
    "\n",
    "    for i in List_all:\n",
    "    #     reduce the prefix and sufix\n",
    "        temp_mark = 0\n",
    "        for j in Wrong_spell:\n",
    "            if j in i:\n",
    "                temp_mark += 1          \n",
    "        if temp_mark>0:\n",
    "            Wrong_spell_List.append(1)\n",
    "        else:\n",
    "            Wrong_spell_List.append(0)\n",
    "        original_len = len(i) - 2 \n",
    "        Each_List = wordninja.split(i)\n",
    "        Name_length.append(len(Each_List))\n",
    "        stand = 0\n",
    "        for j in Each_List:\n",
    "            if str.isdigit(j) is True:\n",
    "                number_mark.append(1)\n",
    "                stand = 1\n",
    "            break\n",
    "        if stand==0:\n",
    "            number_mark.append(0)\n",
    "        longest_element = max([(len(x),x) for x in Each_List])\n",
    "        Ratio = len(longest_element)/original_len\n",
    "        word_dic.append(Ratio)\n",
    "    print(\"The produced word ratio list's length is \",len(word_dic))\n",
    "    print(\"The sample data is\",word_dic[0:6])\n",
    "    return Name_length, Wrong_spell_List,word_dic\n",
    "\n",
    "def Find_Dash_mark(List_all):\n",
    "    Special_mark = []\n",
    "    for i in List_all:\n",
    "        if '-' in i:\n",
    "    #         print(i)\n",
    "            Special_mark.append(1)\n",
    "        else:\n",
    "            Special_mark.append(0)\n",
    "    print(\"The number of domains cotain symbol '-':\",Special_mark.count(1))\n",
    "    return Special_mark\n",
    "    \n",
    "def Count_subdomain(List_all):\n",
    "    sub_domain = []\n",
    "    for i in List_all:\n",
    "        dot_num = i.count('.') \n",
    "        sub_domain.append(dot_num)\n",
    "    return sub_domain\n",
    "\n",
    "def Contain_IP_address(List_all):\n",
    "    import re\n",
    "    Contain_IP_Adress = []\n",
    "    for i in List_all:\n",
    "        IP = re.findall(r\".\\d.\\d.\\d\",i)\n",
    "        if len(IP) == 0:\n",
    "            Contain_IP_Adress.append(0)\n",
    "        else:\n",
    "            Contain_IP_Adress.append(1)\n",
    "    print(\"The number of domain contain IP adress is\",Contain_IP_Adress.count(1))\n",
    "    return Contain_IP_Adress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The produced word ratio list's length is  98251\n",
      "The sample data is [0.13333333333333333, 0.1111111111111111, 0.07407407407407407, 0.09090909090909091, 0.11764705882352941, 0.047619047619047616]\n",
      "The number of domains cotain symbol '-': 24244\n",
      "The number of domain contain IP adress is 10735\n"
     ]
    }
   ],
   "source": [
    "Freenom_top_level_domain = Extract_FTLD(phish_all)\n",
    "Previous_malicious_top_level_domain_TLD = Previous_MTLD(phish_all)\n",
    "Name_length, Wrong_spell_List, word_dic = mixed_feature(phish_all)\n",
    "Special_mark = Find_Dash_mark(phish_all)\n",
    "sub_domain = Count_subdomain(phish_all)\n",
    "Contain_IP_Adress = Contain_IP_address(phish_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The produced word ratio list's length is  98\n",
      "The sample data is [0.09090909090909091, 0.07142857142857142, 0.07142857142857142, 0.07692307692307693, 0.08333333333333333, 0.08333333333333333]\n",
      "The number of domains cotain symbol '-': 24\n",
      "The number of domain contain IP adress is 0\n"
     ]
    }
   ],
   "source": [
    "Freenom_top_level_domain1 = Extract_FTLD(white_final['Unified_url'])\n",
    "Previous_malicious_top_level_domain_TLD1 = Previous_MTLD(white_final['Unified_url'])\n",
    "Name_length1, Wrong_spell_List1, word_dic1 = mixed_feature(white_final['Unified_url'])\n",
    "Special_mark1 = Find_Dash_mark(white_final['Unified_url'])\n",
    "sub_domain1 = Count_subdomain(white_final['Unified_url'])\n",
    "Contain_IP_Adress1 = Contain_IP_address(white_final['Unified_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:30<00:00,  3.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "Alexa_rank_phish_w = []\n",
    "Status_phish_w = []\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "for i in tqdm(white_final['Unified_url']):\n",
    "    url1 = 'https://awis.api.alexa.com/api?Action=UrlInfo&Count=10&ResponseGroup=Rank,LinksInCount&Start=1&Url='\n",
    "    url = url1+i\n",
    "    headers={'x-api-key':'R90lWSm4iC6L6zDUZnZgs8UmqmtUCFrB6fCT2EY5'}\n",
    "    response = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    try:\n",
    "        statuscode = soup.findAll(\"statuscode\")[0].string\n",
    "        if statuscode is None:\n",
    "            Status_phish_w.append(0)\n",
    "        else:\n",
    "            Status_phish_w.append(statuscode)\n",
    "    except (IndexError,ConnectionError):\n",
    "            Status_phish_w.append(0)\n",
    "            print(\"sa\")\n",
    "            print(i)\n",
    "    try:\n",
    "        rank = soup.findAll(\"rank\")[0].string\n",
    "        if rank is None:\n",
    "            Alexa_rank_phish_w.append(0)\n",
    "        else:\n",
    "            Alexa_rank_phish_w.append(rank)\n",
    "    except (IndexError,ConnectionError):\n",
    "            Alexa_rank_phish_w.append(0)\n",
    "            print(\"wa\")\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [01:03<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "way_back_phish_w = []\n",
    "time_stamp_phish_w = []\n",
    "reachable_url_phish_w = []\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "for i in tqdm(white_final['Unified_url']):\n",
    "    try:\n",
    "        url1 = 'https://archive.org/wayback/available?url='\n",
    "        url = url1 + i\n",
    "        response = requests.get(url,timeout=1)\n",
    "        json_data = json.loads(response.text)\n",
    "        status= response.status_code\n",
    "        if status == 200:\n",
    "            reachable_url_phish_w.append(1)\n",
    "        else:\n",
    "            reachable_url_phish_w.append(0)\n",
    "        if bool(json_data['archived_snapshots']) is False:\n",
    "            way_back_phish_w.append(0)\n",
    "            time_stamp_phish_w.append(0)\n",
    "        else:\n",
    "            way_back_phish_w.append(1)\n",
    "            time_stamp_phish_w.append(json_data['archived_snapshots']['closest']['timestamp'])\n",
    "            \n",
    "    except requests.Timeout as err:\n",
    "        way_back_phish_w.append(0)\n",
    "        time_stamp_phish_w.append(0)\n",
    "        reachable_url_phish_w.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unified_url</th>\n",
       "      <th>Reachable_URL</th>\n",
       "      <th>Time_stamp_if_exist</th>\n",
       "      <th>Way_back_archived</th>\n",
       "      <th>Freenom_top_level_domain</th>\n",
       "      <th>Previous_malicious_top_level_domain_TLD</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Wrong_spell_List</th>\n",
       "      <th>word_dic</th>\n",
       "      <th>Special_mark</th>\n",
       "      <th>sub_domain</th>\n",
       "      <th>Contain_IP_Adress</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>Alexa_rank</th>\n",
       "      <th>Status_code</th>\n",
       "      <th>Shortening service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://akkure4covid.com</td>\n",
       "      <td>1</td>\n",
       "      <td>20200401231023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.contracovid.com.br</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://app.contracovid.com.br</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://auxilio.caixa.gov.br</td>\n",
       "      <td>1</td>\n",
       "      <td>20200625035947</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>339</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://bag-coronavirus.ch</td>\n",
       "      <td>1</td>\n",
       "      <td>20200628045649</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>198633</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Unified_url  Reachable_URL Time_stamp_if_exist  \\\n",
       "0        https://akkure4covid.com              1      20200401231023   \n",
       "1  https://api.contracovid.com.br              1                   0   \n",
       "2  https://app.contracovid.com.br              1                   0   \n",
       "3    https://auxilio.caixa.gov.br              1      20200625035947   \n",
       "4      https://bag-coronavirus.ch              1      20200628045649   \n",
       "\n",
       "   Way_back_archived  Freenom_top_level_domain  \\\n",
       "0                  1                         0   \n",
       "1                  0                         0   \n",
       "2                  0                         0   \n",
       "3                  1                         0   \n",
       "4                  1                         0   \n",
       "\n",
       "   Previous_malicious_top_level_domain_TLD  Name_length  Wrong_spell_List  \\\n",
       "0                                        0            7                 0   \n",
       "1                                        0            7                 0   \n",
       "2                                        0            7                 0   \n",
       "3                                        0            8                 0   \n",
       "4                                        0            4                 0   \n",
       "\n",
       "   word_dic  Special_mark  sub_domain  Contain_IP_Adress  \\\n",
       "0  0.090909             0           1                  0   \n",
       "1  0.071429             0           3                  0   \n",
       "2  0.071429             0           3                  0   \n",
       "3  0.076923             0           3                  0   \n",
       "4  0.083333             1           1                  0   \n",
       "\n",
       "   levenshtein_distance Alexa_rank Status_code  Shortening service  \n",
       "0                     5          0         200                   0  \n",
       "1                    10          0         200                   0  \n",
       "2                    10          0         200                   0  \n",
       "3                    13        339         200                   0  \n",
       "4                     6     198633         200                   0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_final['Reachable_URL'] = reachable_url_phish_w\n",
    "white_final['Time_stamp_if_exist'] =  time_stamp_phish_w\n",
    "white_final['Way_back_archived'] = way_back_phish_w\n",
    "white_final['Freenom_top_level_domain'] = Freenom_top_level_domain1 \n",
    "white_final['Previous_malicious_top_level_domain_TLD'] = Previous_malicious_top_level_domain_TLD1\n",
    "white_final['Name_length'] = Name_length1\n",
    "white_final['Wrong_spell_List'] = Wrong_spell_List1\n",
    "white_final['Special_mark'] = Special_mark1\n",
    "white_final['word_dic'] = word_dic1\n",
    "white_final['Contain_IP_Adress'] = Contain_IP_Adress1\n",
    "white_final['Alexa_rank'] = Alexa_rank_phish_w\n",
    "white_final['Status_code'] = Status_phish_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_final = white_final.drop(columns = ['sub_domain1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 54493/98251 [4:29:43<3:33:03,  3.42it/s] "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SSLError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-489048afc8a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rank\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-489048afc8a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mAlexa_rank_phish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mAlexa_rank_phish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SSLError' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "Alexa_rank_phish = []\n",
    "Status_phish = []\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "for i in tqdm(phish_all):\n",
    "    url1 = 'https://awis.api.alexa.com/api?Action=UrlInfo&Count=10&ResponseGroup=Rank,LinksInCount&Start=1&Url='\n",
    "    url = url1+i\n",
    "    headers={'x-api-key':'R90lWSm4iC6L6zDUZnZgs8UmqmtUCFrB6fCT2EY5'}\n",
    "    response = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    try:\n",
    "        statuscode = soup.findAll(\"statuscode\")[0].string\n",
    "        if statuscode is None:\n",
    "            Status_phish.append(0)\n",
    "        else:\n",
    "            Status_phish.append(statuscode)\n",
    "    except (IndexError,ConnectionError):\n",
    "            Status_phish.append(0)\n",
    "            print(\"sa\")\n",
    "            print(i)\n",
    "    try:\n",
    "        rank = soup.findAll(\"rank\")[0].string\n",
    "        if rank is None:\n",
    "            Alexa_rank_phish.append(0)\n",
    "        else:\n",
    "            Alexa_rank_phish.append(rank)\n",
    "    except (IndexError,ConnectionError):\n",
    "            Alexa_rank_phish.append(0)\n",
    "            print(\"wa\")\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 54493/98251 [7:15:15<5:49:30,  2.09it/s]\n",
      "100%|██████████| 43758/43758 [3:52:59<00:00,  3.13it/s]   \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "Alexa_rank_phish2 = []\n",
    "Status_phish2 = []\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "for i in tqdm(phish_all[54493:]):\n",
    "    url1 = 'https://awis.api.alexa.com/api?Action=UrlInfo&Count=10&ResponseGroup=Rank,LinksInCount&Start=1&Url='\n",
    "    url = url1+i\n",
    "    headers={'x-api-key':'R90lWSm4iC6L6zDUZnZgs8UmqmtUCFrB6fCT2EY5'}\n",
    "    response = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    try:\n",
    "        statuscode = soup.findAll(\"statuscode\")[0].string\n",
    "        if statuscode is None:\n",
    "            Status_phish2.append(0)\n",
    "        else:\n",
    "            Status_phish2.append(statuscode)\n",
    "    except (IndexError,ConnectionError):\n",
    "            Status_phish2.append(0)\n",
    "            print(\"sa\")\n",
    "            print(i)\n",
    "    try:\n",
    "        rank = soup.findAll(\"rank\")[0].string\n",
    "        if rank is None:\n",
    "            Alexa_rank_phish2.append(0)\n",
    "        else:\n",
    "            Alexa_rank_phish2.append(rank)\n",
    "    except (IndexError,ConnectionError):\n",
    "            Alexa_rank_phish2.append(0)\n",
    "            print(\"wa\")\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alexa_rank_phish3 = Alexa_rank_phish + Alexa_rank_phish2\n",
    "Status_phish3 = Status_phish[:-1] + Status_phish2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98251\n"
     ]
    }
   ],
   "source": [
    "print(len(phish_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98251/98251 [16:29:43<00:00,  1.65it/s]   \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "way_back_phish = []\n",
    "time_stamp_phish = []\n",
    "reachable_url_phish = []\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "for i in tqdm(phish_all):\n",
    "    try:\n",
    "        url1 = 'https://archive.org/wayback/available?url='\n",
    "        url = url1 + i\n",
    "        response = requests.get(url,timeout=1)\n",
    "        json_data = json.loads(response.text)\n",
    "        status= response.status_code\n",
    "        if status == 200:\n",
    "            reachable_url_phish.append(1)\n",
    "        else:\n",
    "            reachable_url_phish.append(0)\n",
    "        if bool(json_data['archived_snapshots']) is False:\n",
    "            way_back_phish.append(0)\n",
    "            time_stamp_phish.append(0)\n",
    "        else:\n",
    "            way_back_phish.append(1)\n",
    "            time_stamp_phish.append(json_data['archived_snapshots']['closest']['timestamp'])\n",
    "            \n",
    "    except requests.Timeout as err:\n",
    "        way_back_phish.append(0)\n",
    "        time_stamp_phish.append(0)\n",
    "        reachable_url_phish.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98251/98251 [2:10:38<00:00, 12.53it/s]  \n"
     ]
    }
   ],
   "source": [
    "lev_mal_all = cal_min_lev(phish_all,confirmed_phishing_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_phish_tank = {'Unified_url':phish_all,'Reachable_URL':reachable_url_phish,'Time_stamp_if_exist':time_stamp_phish,'Way_back_archived':way_back_phish,\"Freenom_top_level_domain\":Freenom_top_level_domain,\"Previous_malicious_top_level_domain_TLD\":Previous_malicious_top_level_domain_TLD,\"Name_length\":Name_length,\"Wrong_spell_List\":Wrong_spell_List,\"word_dic\":word_dic,\"Special_mark\":Special_mark,\"sub_domain\":sub_domain,\"Contain_Weried_number_combination\":Contain_IP_Adress,\"levenshtein_distance\":lev_mal_all,\"Alexa_rank\":Alexa_rank_phish3,\"Status_code\":Status_phish3}\n",
    "sample_data_phish = pd.DataFrame(dict_phish_tank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_phish.to_csv('data_phish_final2.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freenom_top_level_domain\n",
       "0    228579\n",
       "1       910\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcscan = unlabeled_final.groupby(by=['Freenom_top_level_domain'])\n",
    "dcscan.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\"\n",
    "\n",
    "def shortening_service(url):\n",
    "    match = re.search(shortening_services, url)\n",
    "    return 1 if match else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shortening_service_phish = []\n",
    "Shortening_service_phish2 = []\n",
    "Shortening_service_unlabel = []\n",
    "Shortening_service_white = []\n",
    "\n",
    "for i in sample_data_phish['Unified_url']:\n",
    "    m = shortening_service(i)\n",
    "    Shortening_service_phish.append(m)\n",
    "    \n",
    "for i in white_final['Unified_url']:\n",
    "    m = shortening_service(i)\n",
    "    Shortening_service_white.append(m)\n",
    "    \n",
    "for i in maclious_final['Unified_url']:\n",
    "    m = shortening_service(i)\n",
    "    Shortening_service_phish2.append(m)\n",
    "    \n",
    "for i in unlabeled_final['Unified_url']:\n",
    "    m = shortening_service(i)\n",
    "    Shortening_service_unlabel.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_phish['Shortening service'] = Shortening_service_phish \n",
    "maclious_final['Shortening service'] = Shortening_service_phish2 \n",
    "unlabeled_final['Shortening service'] = Shortening_service_unlabel  \n",
    "white_final['Shortening service'] = Shortening_service_white "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_phish.to_csv('data_phishtank.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "maclious_final.to_csv('maclious_final.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_final.to_csv('unlabeled_final.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_final.to_csv('white_final.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "white_final = pd.read_csv('white_final.csv',sep=',',encoding = \"ISO-8859-1\")\n",
    "maclious_final = pd.read_csv('maclious_final.csv',sep=',',encoding = \"ISO-8859-1\")\n",
    "sample_data_phish = pd.read_csv('data_phishtank.csv',sep=',',encoding = \"ISO-8859-1\")\n",
    "unlabeled_final = pd.read_csv('unlabeled_final.csv',sep=',',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unified_url</th>\n",
       "      <th>Reachable_URL</th>\n",
       "      <th>Time_stamp_if_exist</th>\n",
       "      <th>Way_back_archived</th>\n",
       "      <th>Freenom_top_level_domain</th>\n",
       "      <th>Previous_malicious_top_level_domain_TLD</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Wrong_spell_List</th>\n",
       "      <th>word_dic</th>\n",
       "      <th>Special_mark</th>\n",
       "      <th>sub_domain</th>\n",
       "      <th>Contain_IP_Adress</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>Alexa_rank</th>\n",
       "      <th>Status_code</th>\n",
       "      <th>Shortening service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://akkure4covid.com</td>\n",
       "      <td>1</td>\n",
       "      <td>20200401231023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.contracovid.com.br</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://app.contracovid.com.br</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://auxilio.caixa.gov.br</td>\n",
       "      <td>1</td>\n",
       "      <td>20200625035947</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>339</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://bag-coronavirus.ch</td>\n",
       "      <td>1</td>\n",
       "      <td>20200628045649</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>198633</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Unified_url  Reachable_URL  Time_stamp_if_exist  \\\n",
       "0        https://akkure4covid.com              1       20200401231023   \n",
       "1  https://api.contracovid.com.br              1                    0   \n",
       "2  https://app.contracovid.com.br              1                    0   \n",
       "3    https://auxilio.caixa.gov.br              1       20200625035947   \n",
       "4      https://bag-coronavirus.ch              1       20200628045649   \n",
       "\n",
       "   Way_back_archived  Freenom_top_level_domain  \\\n",
       "0                  1                         0   \n",
       "1                  0                         0   \n",
       "2                  0                         0   \n",
       "3                  1                         0   \n",
       "4                  1                         0   \n",
       "\n",
       "   Previous_malicious_top_level_domain_TLD  Name_length  Wrong_spell_List  \\\n",
       "0                                        0            7                 0   \n",
       "1                                        0            7                 0   \n",
       "2                                        0            7                 0   \n",
       "3                                        0            8                 0   \n",
       "4                                        0            4                 0   \n",
       "\n",
       "   word_dic  Special_mark  sub_domain  Contain_IP_Adress  \\\n",
       "0  0.090909             0           1                  0   \n",
       "1  0.071429             0           3                  0   \n",
       "2  0.071429             0           3                  0   \n",
       "3  0.076923             0           3                  0   \n",
       "4  0.083333             1           1                  0   \n",
       "\n",
       "   levenshtein_distance  Alexa_rank  Status_code  Shortening service  \n",
       "0                     5           0          200                   0  \n",
       "1                    10           0          200                   0  \n",
       "2                    10           0          200                   0  \n",
       "3                    13         339          200                   0  \n",
       "4                     6      198633          200                   0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois\n",
    "from tqdm import tqdm\n",
    "unlabeled_whois_start_unlabel = []\n",
    "unlabeled_whois_end_unlabel = []\n",
    "unknown_TLDcheck_from_whois_unlabel = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9934/229489 [47:41<157:22:25,  2.58s/it]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f6f9a50d8143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhois\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0munlabeled_whois_start_unlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'creation_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0munlabeled_whois_end_unlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'expiration_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jackline/miniconda3/lib/python3.7/site-packages/whois/__init__.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(domain, force, cache_file, slow_down, ignore_returncode)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslow_down\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_returncode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'domain_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jackline/miniconda3/lib/python3.7/site-packages/whois/_1_query.py\u001b[0m in \u001b[0;36mdo_query\u001b[0;34m(dl, force, cache_file, slow_down, ignore_returncode)\u001b[0m\n\u001b[1;32m     44\u001b[0m         CACHE[k] = (\n\u001b[1;32m     45\u001b[0m             \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0m_do_whois_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_returncode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         )\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcache_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jackline/miniconda3/lib/python3.7/site-packages/whois/_1_query.py\u001b[0m in \u001b[0;36m_do_whois_query\u001b[0;34m(dl, ignore_returncode)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \"\"\"\n\u001b[1;32m     60\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'whois'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTDOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mPYTHON_VERSION\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_returncode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jackline/miniconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    924\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# (all known TLD: ['com', 'uk', 'ac_uk', 'ar', 'at', 'pl', 'be', 'biz', 'br', 'ca', 'cc', 'cl', 'club', 'cn', 'co', 'jp', 'co_jp', 'cz', 'de', 'store', 'download', 'edu', 'education', 'eu', 'fi', 'fr', 'id', 'in_', 'info', 'io', 'ir', 'is_is', 'it', 'kr', 'kz', 'lt', 'ru', 'lv', 'me', 'mobi', 'mx', 'name', 'net', 'ninja', 'se', 'nu', 'nyc', 'nz', 'online', 'org', 'pharmacy', 'press', 'pw', 'rest', 'ru_rf', 'security', 'sh', 'site', 'space', 'tech', 'tel', 'theatre', 'tickets', 'tv', 'us', 'uz', 'video', 'website', 'wiki', 'xyz'])\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "for i in tqdm(unlabeled_final['Unified_url']):\n",
    "    try:\n",
    "        try:\n",
    "            domain = whois.query(i)\n",
    "            unlabeled_whois_start_unlabel.append(domain.__dict__['creation_date'])\n",
    "            unlabeled_whois_end_unlabel.append(domain.__dict__['expiration_date'])\n",
    "            unknown_TLDcheck_from_whois_unlabel.append(1)\n",
    "        except AttributeError:\n",
    "            unlabeled_whois_start_unlabel.append(0)\n",
    "            unlabeled_whois_end_unlabel.append(0)\n",
    "            unknown_TLDcheck_from_whois_unlabel.append(1)\n",
    "    except Exception:\n",
    "        unlabeled_whois_start_unlabel.append(0)\n",
    "        unlabeled_whois_end_unlabel.append(0)\n",
    "        unknown_TLDcheck_from_whois_unlabel.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9934\n"
     ]
    }
   ],
   "source": [
    "print(len(unlabeled_whois_end_unlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Pois'...\n",
      "remote: Enumerating objects: 390, done.\u001b[K\n",
      "remote: Total 390 (delta 0), reused 0 (delta 0), pack-reused 390\u001b[K\n",
      "\u001b[KReceiving objects: 100% (390/390), 108.53 KiB | 1.15 MiB/s, done.\n",
      "\u001b[KResolving deltas: 100% (198/198), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/mirhmousavi/Pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pois import *\n",
    "import json\n",
    "# without proxy\n",
    "\n",
    "\n",
    "\n",
    "# (all known TLD: ['com', 'uk', 'ac_uk', 'ar', 'at', 'pl', 'be', 'biz', 'br', 'ca', 'cc', 'cl', 'club', 'cn', 'co', 'jp', 'co_jp', 'cz', 'de', 'store', 'download', 'edu', 'education', 'eu', 'fi', 'fr', 'id', 'in_', 'info', 'io', 'ir', 'is_is', 'it', 'kr', 'kz', 'lt', 'ru', 'lv', 'me', 'mobi', 'mx', 'name', 'net', 'ninja', 'se', 'nu', 'nyc', 'nz', 'online', 'org', 'pharmacy', 'press', 'pw', 'rest', 'ru_rf', 'security', 'sh', 'site', 'space', 'tech', 'tel', 'theatre', 'tickets', 'tv', 'us', 'uz', 'video', 'website', 'wiki', 'xyz'])\n",
    "unlabeled_whois_start_unlabel2 = []\n",
    "unlabeled_whois_end_unlabel2 = []\n",
    "# unknown_TLDcheck_from_whois_unlabel2 = []\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "for i in tqdm(unlabeled_final['Unified_url'][9934:]):\n",
    "    try:\n",
    "        p = Pois(timeout=10)\n",
    "        result = p.fetch(domain=i, whois_server='whois.verisign-grs.com')\n",
    "        creation_date_index = result['registry_result'].find('Creation Date')\n",
    "        expire_date_index = result['registry_result'].find('Registry Expiry Date:')\n",
    "        temp = result['registry_result'].find('Registrar:')\n",
    "        start = result['registry_result'][creation_date_index+len('Creation Date: '):expire_date_index-5]\n",
    "        end = result['registry_result'][expire_date_index+len('Registry Expiry Date: '):temp-5]\n",
    "        if len(start) < 100:\n",
    "            unlabeled_whois_start_unlabel2.append(start)\n",
    "            unlabeled_whois_end_unlabel2.append(end)\n",
    "        else:\n",
    "            unlabeled_whois_start_unlabel2.append(0)\n",
    "            unlabeled_whois_end_unlabel2.append(0)\n",
    "    except Exception as err:\n",
    "        unlabeled_whois_start_unlabel2.append(0)\n",
    "        unlabeled_whois_end_unlabel2.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132040"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_whois_start_unlabel2.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132040"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_whois_end_unlabel2.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pois import *\n",
    "import json# without proxy\n",
    "\n",
    "# (all known TLD: ['com', 'uk', 'ac_uk', 'ar', 'at', 'pl', 'be', 'biz', 'br', 'ca', 'cc', 'cl', 'club', 'cn', 'co', 'jp', 'co_jp', 'cz', 'de', 'store', 'download', 'edu', 'education', 'eu', 'fi', 'fr', 'id', 'in_', 'info', 'io', 'ir', 'is_is', 'it', 'kr', 'kz', 'lt', 'ru', 'lv', 'me', 'mobi', 'mx', 'name', 'net', 'ninja', 'se', 'nu', 'nyc', 'nz', 'online', 'org', 'pharmacy', 'press', 'pw', 'rest', 'ru_rf', 'security', 'sh', 'site', 'space', 'tech', 'tel', 'theatre', 'tickets', 'tv', 'us', 'uz', 'video', 'website', 'wiki', 'xyz'])\n",
    "unlabeled_whois_start_unlabel3 = []\n",
    "unlabeled_whois_end_unlabel3 = []\n",
    "# unknown_TLDcheck_from_whois_unlabel2 = []\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "for i in tqdm(sample_data_phish['Unified_url']):\n",
    "    try:\n",
    "        p = Pois(timeout=10)\n",
    "        result = p.fetch(domain=i, whois_server='whois.verisign-grs.com')\n",
    "        creation_date_index = result['registry_result'].find('Creation Date')\n",
    "        expire_date_index = result['registry_result'].find('Registry Expiry Date:')\n",
    "        temp = result['registry_result'].find('Registrar:')\n",
    "        start = result['registry_result'][creation_date_index+len('Creation Date: '):expire_date_index-5]\n",
    "        end = result['registry_result'][expire_date_index+len('Registry Expiry Date: '):temp-5]\n",
    "        if len(start) < 100:\n",
    "            unlabeled_whois_start_unlabel3.append(start)\n",
    "            unlabeled_whois_end_unlabel3.append(end)\n",
    "        else:\n",
    "            unlabeled_whois_start_unlabel3.append(0)\n",
    "            unlabeled_whois_end_unlabel3.append(0)\n",
    "    except Exception as err:\n",
    "        unlabeled_whois_start_unlabel3.append(0)\n",
    "        unlabeled_whois_end_unlabel3.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47294"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_whois_start_unlabel3.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 86/394 [00:44<12:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time out on quering whois.hostinger.com for 000webhostapp.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 371/394 [03:14<00:19,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on quering whois.net4domains.com for koharrhealth.com, err: 'charmap' codec can't decode byte 0x90 in position 3163: character maps to <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [03:36<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "from pois import *\n",
    "import json\n",
    "# without proxy\n",
    "\n",
    "\n",
    "\n",
    "# (all known TLD: ['com', 'uk', 'ac_uk', 'ar', 'at', 'pl', 'be', 'biz', 'br', 'ca', 'cc', 'cl', 'club', 'cn', 'co', 'jp', 'co_jp', 'cz', 'de', 'store', 'download', 'edu', 'education', 'eu', 'fi', 'fr', 'id', 'in_', 'info', 'io', 'ir', 'is_is', 'it', 'kr', 'kz', 'lt', 'ru', 'lv', 'me', 'mobi', 'mx', 'name', 'net', 'ninja', 'se', 'nu', 'nyc', 'nz', 'online', 'org', 'pharmacy', 'press', 'pw', 'rest', 'ru_rf', 'security', 'sh', 'site', 'space', 'tech', 'tel', 'theatre', 'tickets', 'tv', 'us', 'uz', 'video', 'website', 'wiki', 'xyz'])\n",
    "unlabeled_whois_start_unlabel4 = []\n",
    "unlabeled_whois_end_unlabel4 = []\n",
    "# unknown_TLDcheck_from_whois_unlabel2 = []\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "for i in tqdm(maclious_final['Unified_url']):\n",
    "    try:\n",
    "        p = Pois(timeout=10)\n",
    "        result = p.fetch(domain=i, whois_server='whois.verisign-grs.com')\n",
    "        creation_date_index = result['registry_result'].find('Creation Date')\n",
    "        expire_date_index = result['registry_result'].find('Registry Expiry Date:')\n",
    "        temp = result['registry_result'].find('Registrar:')\n",
    "        start = result['registry_result'][creation_date_index+len('Creation Date: '):expire_date_index-5]\n",
    "        end = result['registry_result'][expire_date_index+len('Registry Expiry Date: '):temp-5]\n",
    "        if len(start) < 100:\n",
    "            unlabeled_whois_start_unlabel4.append(start)\n",
    "            unlabeled_whois_end_unlabel4.append(end)\n",
    "        else:\n",
    "            unlabeled_whois_start_unlabel4.append(0)\n",
    "            unlabeled_whois_end_unlabel4.append(0)\n",
    "    except Exception as err:\n",
    "        unlabeled_whois_start_unlabel4.append(0)\n",
    "        unlabeled_whois_end_unlabel4.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/98 [00:13<03:07,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time out on quering whois.acens.net for coronamadrid.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 62/98 [00:39<00:45,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time out on quering whois.namecheap.com for covid19japan.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:43<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from pois import *\n",
    "import json\n",
    "# without proxy\n",
    "\n",
    "\n",
    "\n",
    "# (all known TLD: ['com', 'uk', 'ac_uk', 'ar', 'at', 'pl', 'be', 'biz', 'br', 'ca', 'cc', 'cl', 'club', 'cn', 'co', 'jp', 'co_jp', 'cz', 'de', 'store', 'download', 'edu', 'education', 'eu', 'fi', 'fr', 'id', 'in_', 'info', 'io', 'ir', 'is_is', 'it', 'kr', 'kz', 'lt', 'ru', 'lv', 'me', 'mobi', 'mx', 'name', 'net', 'ninja', 'se', 'nu', 'nyc', 'nz', 'online', 'org', 'pharmacy', 'press', 'pw', 'rest', 'ru_rf', 'security', 'sh', 'site', 'space', 'tech', 'tel', 'theatre', 'tickets', 'tv', 'us', 'uz', 'video', 'website', 'wiki', 'xyz'])\n",
    "unlabeled_whois_start_unlabel5 = []\n",
    "unlabeled_whois_end_unlabel5 = []\n",
    "# unknown_TLDcheck_from_whois_unlabel2 = []\n",
    "getattr(tqdm, '_instances', {}).clear()\n",
    "for i in tqdm(white_final['Unified_url']):\n",
    "    try:\n",
    "        p = Pois(timeout=10)\n",
    "        result = p.fetch(domain=i, whois_server='whois.verisign-grs.com')\n",
    "        creation_date_index = result['registry_result'].find('Creation Date')\n",
    "        expire_date_index = result['registry_result'].find('Registry Expiry Date:')\n",
    "        temp = result['registry_result'].find('Registrar:')\n",
    "        start = result['registry_result'][creation_date_index+len('Creation Date: '):expire_date_index-5]\n",
    "        end = result['registry_result'][expire_date_index+len('Registry Expiry Date: '):temp-5]\n",
    "        if len(start) < 100:\n",
    "            unlabeled_whois_start_unlabel5.append(start)\n",
    "            unlabeled_whois_end_unlabel5.append(end)\n",
    "        else:\n",
    "            unlabeled_whois_start_unlabel5.append(0)\n",
    "            unlabeled_whois_end_unlabel5.append(0)\n",
    "    except Exception as err:\n",
    "        unlabeled_whois_start_unlabel5.append(0)\n",
    "        unlabeled_whois_end_unlabel5.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, '2021-02-13T08:15:01Z', 0, 0, '2021-03-13T15:47:00Z', 0, '2021-03-17T17:36:29Z', '2021-03-15T00:10:24Z', 0, 0, '2021-03-12T06:13:22Z', '2021-02-14T23:20:53Z', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '2020-09-17T18:31:41Z', 0, '2020-10-29T16:58:56Z', 0, 0, '2020-10-25T04:00:00Z', 0, 0, '2029-11-17T05:00:00Z', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '2021-02-26T13:11:07Z', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '2021-03-20T16:03:02Z', 0, 0, '2021-03-06T15:08:48Z', 0, 0, 0, 0, '2021-02-15T05:06:55Z', '2021-03-14T16:21:36Z', '2022-03-16T22:34:25Z', 0, 0, 0, 0, 0, 0, '2021-01-31T17:03:04Z', '2021-03-14T06:18:02Z', '2021-03-19T16:06:53Z', 0, '2021-03-13T23:42:32Z', '2021-03-11T09:51:02Z', 0, 0, 0, 0, 0, '2021-03-01T13:56:59Z', 0, 0, '2021-03-13T23:23:48Z', '2021-03-11T09:04:18Z', '2021-03-18T04:20:20Z', '2021-02-03T18:13:29Z']\n"
     ]
    }
   ],
   "source": [
    "print(unlabeled_whois_end_unlabel2[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219555/219555 [00:00<00:00, 285849.49it/s]\n",
      "100%|██████████| 219555/219555 [00:00<00:00, 292547.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "temp1_start = []\n",
    "temp1_end = []\n",
    "for i in tqdm(unlabeled_whois_start_unlabel2):\n",
    "    if i != 0:\n",
    "        timestamp = i[0:10]\n",
    "        timestamp1 = datetime.strptime(timestamp,'%Y-%m-%d')\n",
    "        temp1_start.append(timestamp1)\n",
    "    else:\n",
    "        temp1_start.append(0)\n",
    "        \n",
    "for i in tqdm(unlabeled_whois_end_unlabel2):\n",
    "    try:\n",
    "        if i != 0:\n",
    "            timestamp = i[0:10]\n",
    "            timestamp1 = datetime.strptime(timestamp,'%Y-%m-%d')\n",
    "            temp1_end.append(timestamp1)\n",
    "        else:\n",
    "            temp1_end.append(0)\n",
    "    except Exception:\n",
    "        temp1_end.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1_start = unlabeled_whois_start_unlabel + temp1_start\n",
    "temp1_end = unlabeled_whois_end_unlabel + temp1_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98251/98251 [00:00<00:00, 180724.44it/s]\n",
      "100%|██████████| 98251/98251 [00:00<00:00, 265391.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "temp2_start = []\n",
    "temp2_end = []\n",
    "for i in tqdm(unlabeled_whois_start_unlabel3):\n",
    "    if i != 0:\n",
    "        timestamp = i[0:10]\n",
    "        timestamp1 = datetime.strptime(timestamp,'%Y-%m-%d')\n",
    "        temp2_start.append(timestamp1)\n",
    "    else:\n",
    "        temp2_start.append(0)\n",
    "        \n",
    "for i in tqdm(unlabeled_whois_end_unlabel3):\n",
    "    try:\n",
    "        if i != 0:\n",
    "            timestamp = i[0:10]\n",
    "            timestamp1 = datetime.strptime(timestamp,'%Y-%m-%d')\n",
    "            temp2_end.append(timestamp1)\n",
    "        else:\n",
    "            temp2_end.append(0)\n",
    "    except Exception:\n",
    "        temp2_end.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [00:00<00:00, 143913.24it/s]\n",
      "100%|██████████| 394/394 [00:00<00:00, 152901.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "temp3_start = []\n",
    "temp3_end = []\n",
    "for i in tqdm(unlabeled_whois_start_unlabel4):\n",
    "    if i != 0:\n",
    "        timestamp = i[0:10]\n",
    "        timestamp1 = datetime.strptime(timestamp,'%Y-%m-%d')\n",
    "        temp3_start.append(timestamp1)\n",
    "    else:\n",
    "        temp3_start.append(0)\n",
    "        \n",
    "for i in tqdm(unlabeled_whois_end_unlabel4):\n",
    "    try:\n",
    "        if i != 0:\n",
    "            timestamp = i[0:10]\n",
    "            timestamp1 = datetime.strptime(timestamp,'%Y-%m-%d')\n",
    "            temp3_end.append(timestamp1)\n",
    "        else:\n",
    "            temp3_end.append(0)\n",
    "    except Exception:\n",
    "        temp3_end.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [00:00<00:00, 180836.69it/s]\n",
      "100%|██████████| 98/98 [00:00<00:00, 219808.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "temp4_start = []\n",
    "temp4_end = []\n",
    "for i in tqdm(unlabeled_whois_start_unlabel5):\n",
    "    if i != 0:\n",
    "        timestamp = i[0:10]\n",
    "        timestamp1 = datetime.strptime(timestamp,'%Y-%m-%d')\n",
    "        temp4_start.append(timestamp1)\n",
    "    else:\n",
    "        temp4_start.append(0)\n",
    "        \n",
    "for i in tqdm(unlabeled_whois_end_unlabel5):\n",
    "    try:\n",
    "        if i != 0:\n",
    "            timestamp = i[0:10]\n",
    "            timestamp1 = datetime.strptime(timestamp,'%Y-%m-%d')\n",
    "            temp4_end.append(timestamp1)\n",
    "        else:\n",
    "            temp4_end.append(0)\n",
    "    except Exception:\n",
    "        temp4_end.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_phish['start_date'] = temp2_start\n",
    "sample_data_phish['end_date'] = temp2_end\n",
    "\n",
    "unlabeled_final['start_date'] = temp1_start\n",
    "unlabeled_final['end_date'] = temp1_end\n",
    "\n",
    "white_final['start_date'] = temp4_start\n",
    "white_final['end_date'] = temp4_end\n",
    "\n",
    "maclious_final['start_date'] = temp3_start\n",
    "maclious_final['end_date'] = temp3_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unified_url</th>\n",
       "      <th>Reachable_URL</th>\n",
       "      <th>Time_stamp_if_exist</th>\n",
       "      <th>Way_back_archived</th>\n",
       "      <th>Freenom_top_level_domain</th>\n",
       "      <th>Previous_malicious_top_level_domain_TLD</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Wrong_spell_List</th>\n",
       "      <th>word_dic</th>\n",
       "      <th>Special_mark</th>\n",
       "      <th>sub_domain</th>\n",
       "      <th>Contain_IP_Adress</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>Alexa_rank</th>\n",
       "      <th>Status_code</th>\n",
       "      <th>Shortening service</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://0-105.com</td>\n",
       "      <td>1</td>\n",
       "      <td>20180330180702</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10653804</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-04 00:00:00</td>\n",
       "      <td>2020-12-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://0.00000.life</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://000-845int283-000.xyz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://000-hidro-1.info</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://0000.com.my</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7869395</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unified_url  Reachable_URL  Time_stamp_if_exist  \\\n",
       "0              https://0-105.com              1       20180330180702   \n",
       "1           https://0.00000.life              1                    0   \n",
       "2  https://000-845int283-000.xyz              1                    0   \n",
       "3       https://000-hidro-1.info              1                    0   \n",
       "4            https://0000.com.my              0                    0   \n",
       "\n",
       "   Way_back_archived  Freenom_top_level_domain  \\\n",
       "0                  1                         0   \n",
       "1                  0                         0   \n",
       "2                  0                         0   \n",
       "3                  0                         0   \n",
       "4                  0                         0   \n",
       "\n",
       "   Previous_malicious_top_level_domain_TLD  Name_length  Wrong_spell_List  \\\n",
       "0                                        0            4                 0   \n",
       "1                                        0            4                 0   \n",
       "2                                        0            8                 0   \n",
       "3                                        0            6                 0   \n",
       "4                                        0            4                 0   \n",
       "\n",
       "   word_dic  Special_mark  sub_domain  Contain_IP_Adress  \\\n",
       "0  0.133333             1           1                  1   \n",
       "1  0.111111             0           2                  1   \n",
       "2  0.074074             1           1                  1   \n",
       "3  0.090909             1           1                  0   \n",
       "4  0.117647             0           2                  0   \n",
       "\n",
       "   levenshtein_distance  Alexa_rank  Status_code  Shortening service  \\\n",
       "0                     6    10653804          200                   0   \n",
       "1                    10           0          200                   0   \n",
       "2                    17           0          200                   0   \n",
       "3                    10           0          200                   0   \n",
       "4                     6     7869395          200                   0   \n",
       "\n",
       "            start_date             end_date  \n",
       "0  2014-12-04 00:00:00  2020-12-04 00:00:00  \n",
       "1                    0                    0  \n",
       "2                    0                    0  \n",
       "3                    0                    0  \n",
       "4                    0                    0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_phish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_phish = sample_data_phish.drop(columns=['Time_stamp_if_exist'])\n",
    "unlabeled_final = unlabeled_final.drop(columns=['Time_stamp_if_exist'])\n",
    "white_final = white_final.drop(columns=['Time_stamp_if_exist'])\n",
    "maclious_final = maclious_final.drop(columns=['Time_stamp_if_exist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
